{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f974f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.utils.data as Data\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import einsum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "#from sklearn import preprocessing\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from ConLoss import SupConLoss\n",
    "import random\n",
    "import Module as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_it(seed):\n",
    "    random.seed(seed) \n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True \n",
    "    torch.manual_seed(seed)\n",
    "seed = 123\n",
    "seed_it(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load data\n",
    "'''\n",
    "with open('.//data_all.pkl', 'rb') as file:\n",
    "    data_all = pickle.load(file)\n",
    "eeg_data = data_all['eeg_data']\n",
    "emo_label = data_all['emo_label']\n",
    "task_label = data_all['task_label']\n",
    "group = data_all['group']\n",
    "\n",
    "eeg_data.shape, emo_label.shape, task_label.shape, group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\")\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dim, epoch_size, learning_rate, save=True):\n",
    "    test_emo = []\n",
    "    test_task = []\n",
    "    \n",
    "    for k, (train, test) in enumerate(kf.split(eeg_data, emo_label)):\n",
    "\n",
    "        \"\"\" Build Network \"\"\"\n",
    "        model = md.model_1(token_dim=dim, out_put='pred').to(device)\n",
    "        \n",
    "        \"\"\" Optimizer \"\"\"\n",
    "        parameters = model.parameters()\n",
    "        optimizer = torch.optim.Adam(parameters, lr=learning_rate, weight_decay=0.0005)\n",
    "        learning_rate = learning_rate * 0.99\n",
    "\n",
    "        \"\"\" Load data \"\"\"\n",
    "        print('*'*10, '{}-fold'.format(k+1), '*'*10)\n",
    "        train_set = TensorDataset(eeg_data[train], emo_label[train], task_label[train])\n",
    "        test_set = TensorDataset(eeg_data[test], emo_label[test], task_label[test])\n",
    "        train_loader = Data.DataLoader(train_set, batch_size=64)\n",
    "        test_loader = Data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "\n",
    "        for i in range(epoch_size):                                         \n",
    "            loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            model.train()\n",
    "\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc_task = 0.0\n",
    "            for step, (x, y1, y2) in loop:\n",
    "                x, y1, y2 =  Variable(x).to(device), Variable(y1).to(device),  Variable(y2).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred_task= model(x)\n",
    "\n",
    "                loss = criterion(pred_task, y2.long())\n",
    "\n",
    "  \n",
    "                train_loss += loss.item()\n",
    "\n",
    "                pred_task = torch.max(pred_task, 1)[1]\n",
    "                train_correct_task = (pred_task == y2).sum()\n",
    "\n",
    "                train_acc_task += train_correct_task.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loop.set_description(f'Epoch [{i+1} / {epoch_size}]')\n",
    "                loop.set_postfix({\n",
    "                        'loss' : '{:.6f}'.format(train_loss/len(train_set)),\n",
    "                        'acc_task' : '{:.6f}'.format(train_acc_task*100/len(train_set))\n",
    "                                                    })\n",
    "\n",
    "                if i+1 == epoch_size and save == True:   \n",
    "                    model_path = './model_parameter/model1_dim=%s' % (dim)  \n",
    "                    os.makedirs(model_path, exist_ok=True)   \n",
    "                    pkl_name ='KFold=%s.pkl' % (k+1) \n",
    "                    state = {'model':model.state_dict()\n",
    "                            }\n",
    "                    torch.save(state, os.path.join(model_path, pkl_name))\n",
    "        test_loss_all = 0.0\n",
    "        test_loss = 0.0\n",
    "        test_acc_emo = 0.0\n",
    "        test_acc_task = 0.0\n",
    "        task_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y1, y2 in test_loader:\n",
    "                x, y1, y2 = Variable(x).to(device), Variable(y1).to(device), Variable(y2).to(device)\n",
    "\n",
    "                pred_task = model(x)\n",
    "                loss = criterion(pred_task, y2.long())\n",
    "                test_loss_all += loss.item()\n",
    "\n",
    "                pred_test_task = torch.max(pred_task, 1)[1]\n",
    "                test_correct_task = (pred_test_task == y2).sum()\n",
    "                test_acc_task += test_correct_task.item()\n",
    "\n",
    "            print(\n",
    "                'Test Loss: {:.6f},  Test Acc: {:.6f}'.format(test_loss_all / (len(test_set)), test_acc_task * 100 / (len(test_set)))\n",
    "                )\n",
    "\n",
    "\n",
    "        test_task.append(test_acc_task * 100 / (len(test_set)))\n",
    "      \n",
    "        if k+1 == 10 and save == True:  \n",
    "            np.save(os.path.join(model_path, 'result'), test_task)\n",
    "    return test_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b73871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001,\n",
    "               save=True\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
