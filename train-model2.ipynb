{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.utils.data as Data\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import einsum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "#from sklearn import preprocessing\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from ConLoss import SupConLoss\n",
    "import random\n",
    "import Module3 as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_it(seed):\n",
    "    random.seed(seed) \n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.manual_seed(seed)\n",
    "seed = 123\n",
    "seed_it(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load data\n",
    "'''\n",
    "with open('.//data_all.pkl', 'rb') as file:\n",
    "    data_all = pickle.load(file)\n",
    "eeg_data = data_all['eeg_data']\n",
    "emo_label = data_all['emo_label']\n",
    "task_label = data_all['task_label']\n",
    "group = data_all['group']\n",
    "\n",
    "eeg_data.shape, emo_label.shape, task_label.shape, group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\")\n",
    "criterion2 = SupConLoss(temperature=temp)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dim, epoch_size, alpha1, alpha2, alpha3, contrast, learning_rate, save=True):\n",
    "    test_emo = []\n",
    "    test_task = []\n",
    "    #for k, (train, test) in enumerate(logo.split(eeg_data, emo_label, group)):\n",
    "    for k, (train, test) in enumerate(kf.split(eeg_data, emo_label)):\n",
    "\n",
    "        \"\"\" Build Network \"\"\"\n",
    "        model = md.model_2(token_dim=dim).to(device)\n",
    "        \n",
    "        \"\"\" Optimizer \"\"\"\n",
    "        parameters = model.parameters()\n",
    "        optimizer = torch.optim.Adam(parameters, lr=learning_rate, weight_decay=0.0005)\n",
    "        learning_rate = learning_rate * 0.99\n",
    "\n",
    "        \"\"\" Load data \"\"\"\n",
    "        print('*'*10, '{}-fold'.format(k+1), '*'*10)\n",
    "        train_set = TensorDataset(eeg_data[train], emo_label[train], task_label[train])\n",
    "        test_set = TensorDataset(eeg_data[test], emo_label[test], task_label[test])\n",
    "        train_loader = Data.DataLoader(train_set, batch_size=64)\n",
    "        test_loader = Data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "\n",
    "        for i in range(epoch_size):                                         \n",
    "            loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc_task = 0.0\n",
    "            for step, (x, y1, y2) in loop:\n",
    "                x, y1, y2 =  Variable(x).to(device), Variable(y1).to(device),  Variable(y2).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred_task, emo_enc, task_enc = model(x)\n",
    "\n",
    "                loss1 = criterion1(pred_task, y2.long())\n",
    "\n",
    "                loss2 = criterion2(emo_enc, y1.long())      \n",
    "               \n",
    "                loss3 = criterion2(task_enc, y2.long())                                 \n",
    "\n",
    "                if contrast == 'emo':\n",
    "                    loss = alpha1 * loss1 + alpha2 * loss2\n",
    "                if contrast == 'task':\n",
    "                    loss = alpha1 * loss1 + alpha3 * loss3\n",
    "                if contrast == 'all':\n",
    "                    loss = alpha1 * loss1 + alpha2 * loss2 + alpha3 * loss3\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                pred_task = torch.max(pred_task, 1)[1]\n",
    "                train_correct_task = (pred_task == y2).sum()\n",
    "\n",
    "                train_acc_task += train_correct_task.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loop.set_description(f'Epoch [{i+1} / {epoch_size}]')\n",
    "                loop.set_postfix({\n",
    "                        'loss' : '{:.6f}'.format(train_loss/len(train_set)),\n",
    "                        'acc_task' : '{:.6f}'.format(train_acc_task*100/len(train_set))\n",
    "                                                    })\n",
    "  \n",
    "                if i+1 == epoch_size and save == True:   \n",
    "                    model_path = './model_parameter/model2_cls=%s_emo=%s_task=%s_dim=%s_temp=%s_contrast=%s' % (alpha1, alpha2, alpha3, dim, temp, contrast)  #文件夹名称\n",
    "                    os.makedirs(model_path, exist_ok=True)   \n",
    "                    pkl_name ='KFold=%s.pkl' % (k+1)  \n",
    "                    state = {'model':model.state_dict()\n",
    "                            }\n",
    "                    torch.save(state, os.path.join(model_path, pkl_name))\n",
    "        test_loss_all = 0.0\n",
    "        test_loss = 0.0\n",
    "        test_acc_emo = 0.0\n",
    "        test_acc_task = 0.0\n",
    "        task_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y1, y2 in test_loader:\n",
    "                x, y1, y2 = Variable(x).to(device), Variable(y1).to(device), Variable(y2).to(device)\n",
    "\n",
    "                pred_task, emo_enc, task_enc = model(x)\n",
    "                loss = criterion1(pred_task, y2.long())\n",
    "                test_loss_all += loss.item()\n",
    "\n",
    "                pred_test_task = torch.max(pred_task, 1)[1]\n",
    "                test_correct_task = (pred_test_task == y2).sum()\n",
    "                test_acc_task += test_correct_task.item()\n",
    "\n",
    "            print(\n",
    "                'Test Loss: {:.6f},  Test Acc: {:.6f}'.format(test_loss_all / (len(test_set)), test_acc_task * 100 / (len(test_set)))\n",
    "                )\n",
    "\n",
    "\n",
    "        test_task.append(test_acc_task * 100 / (len(test_set)))\n",
    "\n",
    "        if k+1 == 10 and save == True:  \n",
    "            np.save(os.path.join(model_path, 'result'), test_task)\n",
    "    return test_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b73871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001, \n",
    "               alpha1=1, alpha2=0.5, alpha3=0.5, contrast='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cc9758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001, \n",
    "               alpha1=1, alpha2=0.05, alpha3=0.05, contrast='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bef44b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001, \n",
    "               alpha1=1, alpha2=5, alpha3=5, contrast='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bccaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001, \n",
    "               alpha1=1, alpha2=0.5, alpha3=0, contrast='emo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e22c142",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "               learning_rate=0.001, \n",
    "               alpha1=1, alpha2=0, alpha3=0.5, contrast='emo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3eca44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043f22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d04c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2fb19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2a721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
