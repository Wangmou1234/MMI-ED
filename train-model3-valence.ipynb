{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05dffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import interpolate\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.utils.data as Data\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import einsum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, LeaveOneGroupOut\n",
    "import copy\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "#from sklearn import preprocessing\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from ConLoss import SupConLoss\n",
    "import random\n",
    "import Module as md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_it(seed):\n",
    "    random.seed(seed) \n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    torch.backends.cudnn.enabled = True  \n",
    "    torch.manual_seed(seed)\n",
    "seed = 123\n",
    "seed_it(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "load data\n",
    "'''\n",
    "with open('.//data_all.pkl', 'rb') as file:\n",
    "    data_all = pickle.load(file)\n",
    "eeg_data = data_all['eeg_data']\n",
    "emo_label = data_all['emo_label']\n",
    "task_label = data_all['task_label']\n",
    "group = data_all['group']\n",
    "emo_discrete_label = data_all['emo_discrete_label'] \n",
    "eeg_data.shape, emo_label.shape, task_label.shape, group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f237ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=1\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\")\n",
    "criterion2 = SupConLoss(temperature=temp)\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "logo = LeaveOneGroupOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dim, epoch_size, alpha1, alpha2, alpha3, alpha4, alpha5, contrast, learning_rate, GRL, save=True):\n",
    "    test_emo = []\n",
    "    test_task = []\n",
    "\n",
    " \n",
    "    for k, (train, test) in enumerate(kf.split(eeg_data, emo_label)):\n",
    "\n",
    "        \"\"\" Build Network \"\"\"\n",
    "        model = md.model_3(token_dim=dim, out_put='all', device='cuda:0', GRL=GRL).to(device)\n",
    "        \n",
    "        \"\"\" Optimizer \"\"\"\n",
    "        parameters = model.parameters()\n",
    "        optimizer = torch.optim.Adam(parameters, lr=learning_rate, weight_decay=0.0005)\n",
    "        learning_rate = learning_rate * 0.99\n",
    "        \n",
    "        \"\"\" Load data \"\"\"\n",
    "        print('*'*10, '{}-fold'.format(k+1), '*'*10)\n",
    "        train_set = TensorDataset(eeg_data[train], emo_label[train], task_label[train], emo_discrete_label[train])\n",
    "        test_set = TensorDataset(eeg_data[test], emo_label[test], task_label[test], emo_discrete_label[test])\n",
    "        train_loader = Data.DataLoader(train_set, batch_size=64)\n",
    "        test_loader = Data.DataLoader(test_set, batch_size=1)\n",
    "\n",
    "\n",
    "        for i in range(epoch_size):                                          \n",
    "            loop = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "            model.train()\n",
    "\n",
    "            train_loss = 0.0\n",
    "            train_acc_task = 0.0\n",
    "            for step, (x, y1, y2, y3) in loop:\n",
    "                x, y1, y2, y3 =  Variable(x).to(device), Variable(y1).to(device), Variable(y2).to(device), Variable(y3).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                pred_task, emo_enc, task_enc, joint, marginal = model(x)\n",
    "                \n",
    "   \n",
    "                                \n",
    "                loss1 = criterion1(pred_task, y2.long())     \n",
    "                \n",
    "             \n",
    "                loss2 = criterion2(emo_enc, y1.long())      \n",
    "                \n",
    "       \n",
    "                loss3 = criterion2(task_enc, y2.long())                  \n",
    "                \n",
    "             \n",
    "                loss4 = - md.estimate_JSD_MI(joint, marginal, True)\n",
    "                \n",
    "              \n",
    "                loss5 = criterion2(emo_enc, y3.long())          \n",
    "                \n",
    "                \n",
    "                if contrast == 'emo':\n",
    "                    loss = alpha1 * loss1 + alpha2 * loss2 + alpha4 * loss4\n",
    "                if contrast == 'task':\n",
    "                    loss = alpha1 * loss1 + alpha3 * loss3 + alpha4 * loss4\n",
    "                if contrast == 'all':\n",
    "                    loss = alpha1 * loss1 + alpha2 * loss2 + alpha3 * loss3 + alpha4 * loss4 + alpha5 * loss5\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                pred_task = torch.max(pred_task, 1)[1]\n",
    "                train_correct_task = (pred_task == y2).sum()\n",
    "\n",
    "                train_acc_task += train_correct_task.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loop.set_description(f'Epoch [{i+1} / {epoch_size}]')\n",
    "                loop.set_postfix({\n",
    "                        'loss' : '{:.6f}'.format(train_loss/len(train_set)),\n",
    "                        'acc_task' : '{:.6f}'.format(train_acc_task*100/len(train_set))\n",
    "                                                    })\n",
    "       \n",
    "                if i+1 == epoch_size and save == True:   \n",
    "                    model_path = './model_parameter/model3_cls=%s_emo=%s_task=%s_mi=%s_emo_d=%s_dim=%s_temp=%s_GRL=%s_valence' % (alpha1, alpha2, alpha3, alpha4, alpha5, dim, temp, GRL)  \n",
    "                    os.makedirs(model_path, exist_ok=True)   \n",
    "                    pkl_name ='KFold=%s.pkl' % (k+1)  \n",
    "                    state = {'model':model.state_dict()\n",
    "                            }\n",
    "                    torch.save(state, os.path.join(model_path, pkl_name))\n",
    "                \n",
    "        test_loss_all = 0.0\n",
    "        test_loss = 0.0\n",
    "        test_acc_emo = 0.0\n",
    "        test_acc_task = 0.0\n",
    "        task_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "\n",
    "            for x, y1, y2, y3 in test_loader:\n",
    "                x, y1, y2, y3 = Variable(x).to(device), Variable(y1).to(device), Variable(y2).to(device), Variable(y3).to(device)\n",
    "\n",
    "                pred_task, emo_enc, task_enc, joint, marginal = model(x)\n",
    "\n",
    "                loss = criterion1(pred_task, y2.long())\n",
    "                test_loss_all += loss.item()\n",
    "\n",
    "                pred_test_task = torch.max(pred_task, 1)[1]\n",
    "                test_correct_task = (pred_test_task == y2).sum()\n",
    "                test_acc_task += test_correct_task.item()\n",
    "\n",
    "            print(\n",
    "                'Test Loss: {:.6f},  Test Acc: {:.6f}'.format(test_loss_all / (len(test_set)), test_acc_task * 100 / (len(test_set)))\n",
    "                )\n",
    "\n",
    "\n",
    "        test_task.append(test_acc_task * 100 / (len(test_set)))\n",
    "       \n",
    "        if k+1 == 10 and save == True:\n",
    "            np.save(os.path.join(model_path, 'result'), test_task)\n",
    "    return test_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = train(dim=128, epoch_size=50, \n",
    "                   learning_rate=0.001, \n",
    "                   alpha1=1, alpha2=0, alpha3=0.5, alpha4=0.1, alpha5=0.5,\n",
    "                   contrast='all', GRL=False, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
